{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelpy Tutorial\n",
    "\n",
    "The aim of this notebook is to showcase the capabilities of the Novelpy package using a controlled sample. We will discuss the different features we have implemented and those that we intend to add in the future. This notebook exclusively operates with JSON. However, please note that for RAM and, sometimes, speed efficiency, we typically use MongoDB. If you prefer to use MongoDB, make sure to refer to this notebook instead:[ Novelpy MongoDB Tutorial ](https://github.com/Kwirtz/novelpy/tutorial/tuts_MongoDB.ipynb)(only few lines changes to allow connection to MongoDB, for the comments and information still refer to the actual notebook).\n",
    "\n",
    "Structure of the Notebook:\n",
    "- [First steps and presentation of the data.](#first-steps-and-presentation-of-the-data)\n",
    "- [Computation for co-ocurence based novelty indicators.](#computation-for-co-ocurence-based-novelty-indicators)\n",
    "- [Computation for text based novelty indicators.](#computation-for-text-based-novelty-indicators)\n",
    "- [Computation for disruption indicators.](#computation-for-disruption-indicators)\n",
    "\n",
    "<a name=\"first-steps-and-presentation-of-the-data\"></a>\n",
    "## First steps and presentation of the data.\n",
    "\n",
    "First we recommend you create a specific environment. We use SciPy and it tends to be tricky in terms of compatiblity issues. Then create a project folder and you need to add the en_core_sci_lg folder inside (you can find it here https://allenai.github.io/scispacy/) and the path to the files should be like this en_core_sci_lg-0.5.3\\en_core_sci_lg\\en_core_sci_lg-0.5.3. As you can see we use the 0.5.3 version we will tell you when to change it if you have another version.\n",
    "\n",
    "We have provided a small sample of data to help you become acquainted with the package and the required data structure. To obtain this sample, one needs to run the following code in the \"project\" folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Citation_net_sample.zip: 100%|██████████| 191M/191M [02:54<00:00, 1.15MiB/s] \n",
      "Meshterms_sample.zip: 100%|██████████| 149M/149M [02:42<00:00, 965kiB/s]  \n",
      "Ref_Journals_sample.zip: 100%|██████████| 16.0M/16.0M [00:08<00:00, 2.04MiB/s]\n",
      "Title_abs_sample.zip: 100%|██████████| 784M/784M [10:48<00:00, 1.27MiB/s]  \n",
      "authors_sample.zip: 100%|██████████| 396M/396M [07:01<00:00, 987kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from novelpy.utils.get_sample import download_sample\n",
    "download_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a folder named \"Data\" with various subfolders inside. Within each subfolder, you will find a JSON file for each year. Most Novelty indicator work at the year level, explaining the choice of a file per year. Then depending on which indicator you run you need different information. Please refer to this paper https://arxiv.org/abs/2211.10346 if you want to learn more about the conceptual framework.\n",
    "\n",
    "### Co-occurence novelty based indicators\n",
    "Let us start with the indicators that use a matrix of co-occurence. These indicator look at either the combination of journals in the references of a paper or the combination of keywords (in the case of PubMed MeshTerms). The conceptual idea behind it is that no new knowledge comes from scratch. New knowledge is just combination of past knowledge. The assumption here is that knowledge is represented by keywords or journal categories. Here's a list of these indicators: Uzzi et al. (2013), Foster et al. (2015), Lee et al. (2015), Wang et al. (2017)\n",
    "\n",
    "For these indicators you will only work folders Meshterms_sample or Ref_Journals_sample you got from the sample. For the indicators of Foster et al., Lee et al. and Wang et al. you only need three information for a document. The ID of a document, the year of creation of the document and the entities they use. So each JSON file will be a list of dictionaries. Here is the example of a single dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Ref_Journals = {\"PMID\": 16992327, \"year\": 1896, \"c04_referencelist\": [{\"item\": \"0022-3751\"}]}\n",
    "\n",
    "#OR\n",
    "\n",
    "dict_Meshterms = {\"PMID\": 12255534, \"year\": 1902, \"Mesh_year_category\": [{\"descUI\": \"D000830\"}, {\"descUI\": \"D001695\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the indicator of Uzzi et al. you also need the year of creation of the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Ref_Journals = {\"PMID\": 16992327, \"year\": 1896, \"c04_referencelist\": [{\"item\": \"0022-3751\", \"year\": 1893}]}\n",
    "\n",
    "#OR\n",
    "\n",
    "dict_Meshterms = {\"PMID\": 12255534, \"year\": 1902, \"Mesh_year_category\": [{\"descUI\": \"D000830\", \"year\": 1999}, {\"descUI\": \"D001695\", \"year\": 1999}]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text based Novelty indicators\n",
    "\n",
    "\n",
    "Indicators of novelty derived from text operate on the premise that knowledge is encapsulated within the abstract, title, or keywords of a document. These indicators employ a text embedding technique, typically utilizing word2vec, to establish a measure of distance between words. The greater the distance between two words, the less frequently they co-occur. Therefore, when a document employs words that are particularly distant from each other, it is deemed novel. Novelpy supports two such indicators: one proposed by Shibayama et al. (2021) and another by Pelletier and Wirtz (2023).\n",
    "\n",
    "To run Shibayama et al. (2021), one needs the Citation_net_sample (i.e. a list of the ID of papers the document cite and not only) but also Title_abs_sample in which you will find the abstract and/or title of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_citation_net = {\"PMID\": 20793277, \"year\": 1850, \"refs_pmid_wos\": [20794613, 20794649, 20794685, 20794701, 20794789, 20794829]}\n",
    "\n",
    "#AND\n",
    "\n",
    "dict_title_abs = {\"PMID\": 20793277, \"year\": 1850, \"ArticleTitle\": \"Here is the title\", \"a04_abstract\":[{\"AbstractText\":\"This is the abstract\"}]}\n",
    "#Or You can also have the following format for title abs. In this case leave the abstract_sub_variable argument empty\n",
    "dict_title_abs = {\"PMID\": 20793277, \"year\": 1850, \"ArticleTitle\": \"Here is the title\", \"a04_abstract\":\"This is the abstract\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Pelletier et Wirtz (2023) you need the Title_abs_sample but also authors_sample in which you will find the list of the Authors of a document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_authors_list = {\"PMID\": 20793277, \"year\": 1850, \"a02_authorlist\": [{\"id\":201645},{\"id\":51331354}]}\n",
    "\n",
    "#AND\n",
    "\n",
    "dict_title_abs = {\"PMID\": 20793277, \"year\": 1850, \"ArticleTitle\": \"Here is the title\", \"a04_abstract\":[{\"AbstractText\":\"This is the abstract\"}]}\n",
    "#Or You can also have the following format for title abs. In this case leave the abstract_sub_variable argument empty\n",
    "dict_title_abs = {\"PMID\": 20793277, \"year\": 1850, \"ArticleTitle\": \"Here is the title\", \"a04_abstract\":\"This is the abstract\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disruption indicators\n",
    "\n",
    "Finally, for disruptiveness indicators, one only need the Citation_net_sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_citation_net = {\"PMID\": 20793277, \"year\": 1850, \"refs_pmid_wos\": [20794613, 20794649, 20794685, 20794701, 20794789, 20794829]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"computation-for-co-ocurence-based-novelty-indicators\"></a>\n",
    "## Computation for co-ocurence based novelty indicators \n",
    "\n",
    "We have 4 co-occurence based indicators Uzzi et al., Foster et al., Lee et al., Wang et al.\n",
    "We first start by computing the co-ocurence matrices (i.e pairwise usage of items). It does not matter if the original data is in JSON or on MongoDB, these co-ocurence matrices are saved in the pickle format in Data/docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get item list, loop on every doc: 100%|██████████| 38874/38874 [00:00<00:00, 747583.12it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 40946/40946 [00:00<00:00, 926831.22it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 42302/42302 [00:00<00:00, 1082587.61it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 44803/44803 [00:00<00:00, 1018279.66it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 46779/46779 [00:00<00:00, 974604.09it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 49872/49872 [00:00<00:00, 941002.77it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 52046/52046 [00:00<00:00, 442428.24it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 54721/54721 [00:00<00:00, 901634.65it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 58439/58439 [00:00<00:00, 979883.23it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 62241/62241 [00:00<00:00, 881073.51it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 67361/67361 [00:00<00:00, 898140.39it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 70501/70501 [00:00<00:00, 829430.14it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 75717/75717 [00:00<00:00, 946438.02it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 81228/81228 [00:00<00:00, 620066.51it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 84496/84496 [00:00<00:00, 844962.82it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 89168/89168 [00:00<00:00, 946166.10it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 93185/93185 [00:00<00:00, 818742.16it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 100470/100470 [00:00<00:00, 648815.42it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 103192/103192 [00:00<00:00, 637696.46it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106454/106454 [00:00<00:00, 718837.94it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106557/106557 [00:00<00:00, 755268.59it/s]\n",
      "for every year: 100%|██████████| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Populate matrix: 100%|██████████| 38874/38874 [00:04<00:00, 9344.08it/s] \n",
      "Populate matrix: 100%|██████████| 40946/40946 [00:00<00:00, 46317.02it/s]\n",
      "Populate matrix: 100%|██████████| 42302/42302 [00:00<00:00, 58980.66it/s]\n",
      "Populate matrix: 100%|██████████| 44803/44803 [00:00<00:00, 53465.47it/s]\n",
      "Populate matrix: 100%|██████████| 46779/46779 [00:00<00:00, 47637.92it/s]\n",
      "Populate matrix: 100%|██████████| 49872/49872 [00:01<00:00, 48503.98it/s]\n",
      "Populate matrix: 100%|██████████| 52046/52046 [00:01<00:00, 44265.21it/s]\n",
      "Populate matrix: 100%|██████████| 54721/54721 [00:01<00:00, 47031.56it/s]\n",
      "Populate matrix: 100%|██████████| 58439/58439 [00:01<00:00, 51108.59it/s]\n",
      "Populate matrix: 100%|██████████| 62241/62241 [00:01<00:00, 43558.09it/s]\n",
      "Populate matrix: 100%|██████████| 67361/67361 [00:02<00:00, 28873.21it/s]\n",
      "Populate matrix: 100%|██████████| 70501/70501 [00:01<00:00, 55820.53it/s]\n",
      "Populate matrix: 100%|██████████| 75717/75717 [00:01<00:00, 57145.63it/s]\n",
      "Populate matrix: 100%|██████████| 81228/81228 [00:01<00:00, 63874.79it/s]\n",
      "Populate matrix: 100%|██████████| 84496/84496 [00:01<00:00, 64178.58it/s]\n",
      "Populate matrix: 100%|██████████| 89168/89168 [00:01<00:00, 56579.55it/s]\n",
      "Populate matrix: 100%|██████████| 93185/93185 [00:01<00:00, 67666.57it/s]\n",
      "Populate matrix: 100%|██████████| 100470/100470 [00:01<00:00, 50399.70it/s]\n",
      "Populate matrix: 100%|██████████| 103192/103192 [00:01<00:00, 64539.43it/s]\n",
      "Populate matrix: 100%|██████████| 106454/106454 [00:01<00:00, 65032.53it/s]\n",
      "Populate matrix: 100%|██████████| 106557/106557 [00:01<00:00, 59419.92it/s]\n",
      "For each year in range: 100%|██████████| 21/21 [00:40<00:00,  1.91s/it]\n",
      "Get item list, loop on every doc: 100%|██████████| 38874/38874 [00:00<00:00, 877879.16it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 40946/40946 [00:00<00:00, 1033644.13it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 42302/42302 [00:00<00:00, 1014479.82it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 44803/44803 [00:00<00:00, 1018246.56it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 46779/46779 [00:00<00:00, 917250.32it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 49872/49872 [00:00<00:00, 997402.90it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 52046/52046 [00:00<00:00, 839464.03it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 54721/54721 [00:00<00:00, 927425.62it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 58439/58439 [00:00<00:00, 990491.27it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 62241/62241 [00:00<00:00, 818976.21it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 67361/67361 [00:00<00:00, 874813.87it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 70501/70501 [00:00<00:00, 968151.87it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 75717/75717 [00:00<00:00, 890802.83it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 81228/81228 [00:00<00:00, 938421.67it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 84496/84496 [00:00<00:00, 889420.15it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 89168/89168 [00:00<00:00, 895972.41it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 93185/93185 [00:00<00:00, 1072151.01it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 100470/100470 [00:00<00:00, 1067488.41it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 103192/103192 [00:00<00:00, 1056134.29it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106454/106454 [00:00<00:00, 993112.58it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106557/106557 [00:00<00:00, 917708.81it/s]\n",
      "for every year: 100%|██████████| 21/21 [00:05<00:00,  3.90it/s]\n",
      "Populate matrix: 100%|██████████| 38874/38874 [00:01<00:00, 28354.47it/s]\n",
      "Populate matrix: 100%|██████████| 40946/40946 [00:00<00:00, 102574.68it/s]\n",
      "Populate matrix: 100%|██████████| 42302/42302 [00:00<00:00, 111570.71it/s]\n",
      "Populate matrix: 100%|██████████| 44803/44803 [00:00<00:00, 79595.56it/s]\n",
      "Populate matrix: 100%|██████████| 46779/46779 [00:00<00:00, 82086.35it/s]\n",
      "Populate matrix: 100%|██████████| 49872/49872 [00:00<00:00, 79376.52it/s]\n",
      "Populate matrix: 100%|██████████| 52046/52046 [00:00<00:00, 78231.04it/s]\n",
      "Populate matrix: 100%|██████████| 54721/54721 [00:00<00:00, 79753.77it/s]\n",
      "Populate matrix: 100%|██████████| 58439/58439 [00:00<00:00, 74393.40it/s]\n",
      "Populate matrix: 100%|██████████| 62241/62241 [00:00<00:00, 73586.94it/s]\n",
      "Populate matrix: 100%|██████████| 67361/67361 [00:01<00:00, 64449.99it/s]\n",
      "Populate matrix: 100%|██████████| 70501/70501 [00:00<00:00, 84272.60it/s]\n",
      "Populate matrix: 100%|██████████| 75717/75717 [00:00<00:00, 76461.14it/s]\n",
      "Populate matrix: 100%|██████████| 81228/81228 [00:00<00:00, 81907.53it/s]\n",
      "Populate matrix: 100%|██████████| 84496/84496 [00:01<00:00, 83303.42it/s]\n",
      "Populate matrix: 100%|██████████| 89168/89168 [00:01<00:00, 83765.23it/s]\n",
      "Populate matrix: 100%|██████████| 93185/93185 [00:01<00:00, 85242.76it/s]\n",
      "Populate matrix: 100%|██████████| 100470/100470 [00:01<00:00, 77756.68it/s]\n",
      "Populate matrix: 100%|██████████| 103192/103192 [00:01<00:00, 88019.75it/s]\n",
      "Populate matrix: 100%|██████████| 106454/106454 [00:01<00:00, 82387.21it/s]\n",
      "Populate matrix: 100%|██████████| 106557/106557 [00:01<00:00, 86240.66it/s]\n",
      "For each year in range: 100%|██████████| 21/21 [00:25<00:00,  1.24s/it]\n",
      "Get item list, loop on every doc: 100%|██████████| 38874/38874 [00:00<00:00, 312075.33it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 40946/40946 [00:00<00:00, 284197.48it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 42302/42302 [00:00<00:00, 212963.62it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 44803/44803 [00:00<00:00, 260628.62it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 46779/46779 [00:00<00:00, 190518.93it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 49872/49872 [00:00<00:00, 221134.87it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 52046/52046 [00:00<00:00, 229662.03it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 54721/54721 [00:00<00:00, 225532.70it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 58439/58439 [00:00<00:00, 156672.06it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 62241/62241 [00:00<00:00, 198480.53it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 67361/67361 [00:00<00:00, 236831.79it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 70501/70501 [00:00<00:00, 216409.05it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 75717/75717 [00:00<00:00, 237652.21it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 81228/81228 [00:00<00:00, 270911.83it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 84496/84496 [00:00<00:00, 224364.22it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 89168/89168 [00:00<00:00, 212645.49it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 93185/93185 [00:00<00:00, 231795.54it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 100470/100470 [00:00<00:00, 206609.78it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 103192/103192 [00:00<00:00, 206384.10it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106454/106454 [00:00<00:00, 232795.05it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106557/106557 [00:00<00:00, 218821.31it/s]\n",
      "for every year: 100%|██████████| 21/21 [00:39<00:00,  1.88s/it]\n",
      "Populate matrix: 100%|██████████| 38874/38874 [00:41<00:00, 939.05it/s]\n",
      "Populate matrix: 100%|██████████| 40946/40946 [00:42<00:00, 954.36it/s] \n",
      "Populate matrix: 100%|██████████| 42302/42302 [00:43<00:00, 965.08it/s]\n",
      "Populate matrix: 100%|██████████| 44803/44803 [00:47<00:00, 937.44it/s]\n",
      "Populate matrix: 100%|██████████| 46779/46779 [00:50<00:00, 930.98it/s]\n",
      "Populate matrix: 100%|██████████| 49872/49872 [00:55<00:00, 905.61it/s]\n",
      "Populate matrix: 100%|██████████| 52046/52046 [00:59<00:00, 881.88it/s]\n",
      "Populate matrix: 100%|██████████| 54721/54721 [01:02<00:00, 873.52it/s]\n",
      "Populate matrix: 100%|██████████| 58439/58439 [01:07<00:00, 859.50it/s]\n",
      "Populate matrix: 100%|██████████| 62241/62241 [01:12<00:00, 856.73it/s]\n",
      "Populate matrix: 100%|██████████| 67361/67361 [01:16<00:00, 878.14it/s]\n",
      "Populate matrix: 100%|██████████| 70501/70501 [01:12<00:00, 977.61it/s]\n",
      "Populate matrix: 100%|██████████| 75717/75717 [01:16<00:00, 984.61it/s] \n",
      "Populate matrix: 100%|██████████| 81228/81228 [01:22<00:00, 984.35it/s] \n",
      "Populate matrix: 100%|██████████| 84496/84496 [01:25<00:00, 987.78it/s]\n",
      "Populate matrix: 100%|██████████| 89168/89168 [01:33<00:00, 951.50it/s]\n",
      "Populate matrix: 100%|██████████| 93185/93185 [01:36<00:00, 961.57it/s] \n",
      "Populate matrix: 100%|██████████| 100470/100470 [01:45<00:00, 950.76it/s]\n",
      "Populate matrix: 100%|██████████| 103192/103192 [01:40<00:00, 1024.71it/s]\n",
      "Populate matrix: 100%|██████████| 106454/106454 [01:40<00:00, 1056.38it/s]\n",
      "Populate matrix: 100%|██████████| 106557/106557 [01:40<00:00, 1058.35it/s]\n",
      "For each year in range: 100%|██████████| 21/21 [26:17<00:00, 75.13s/it] \n",
      "Get item list, loop on every doc: 100%|██████████| 38874/38874 [00:00<00:00, 306255.82it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 40946/40946 [00:00<00:00, 304951.19it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 42302/42302 [00:00<00:00, 290918.56it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 44803/44803 [00:00<00:00, 285244.99it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 46779/46779 [00:00<00:00, 260216.88it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 49872/49872 [00:00<00:00, 297235.97it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 52046/52046 [00:00<00:00, 260443.54it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 54721/54721 [00:00<00:00, 243108.98it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 58439/58439 [00:00<00:00, 269157.46it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 62241/62241 [00:00<00:00, 271871.92it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 67361/67361 [00:00<00:00, 273821.17it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 70501/70501 [00:00<00:00, 256067.92it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 75717/75717 [00:00<00:00, 268634.39it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 81228/81228 [00:00<00:00, 258101.24it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 84496/84496 [00:00<00:00, 250600.45it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 89168/89168 [00:00<00:00, 277500.71it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 93185/93185 [00:00<00:00, 212620.49it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 100470/100470 [00:00<00:00, 216011.62it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 103192/103192 [00:00<00:00, 251754.95it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106454/106454 [00:00<00:00, 245617.09it/s]\n",
      "Get item list, loop on every doc: 100%|██████████| 106557/106557 [00:00<00:00, 256150.67it/s]\n",
      "for every year: 100%|██████████| 21/21 [00:33<00:00,  1.62s/it]\n",
      "Populate matrix: 100%|██████████| 38874/38874 [00:37<00:00, 1027.41it/s]\n",
      "Populate matrix: 100%|██████████| 40946/40946 [00:39<00:00, 1030.07it/s]\n",
      "Populate matrix: 100%|██████████| 42302/42302 [00:42<00:00, 1003.10it/s]\n",
      "Populate matrix: 100%|██████████| 44803/44803 [00:46<00:00, 968.83it/s]\n",
      "Populate matrix: 100%|██████████| 46779/46779 [00:49<00:00, 953.84it/s]\n",
      "Populate matrix: 100%|██████████| 49872/49872 [00:53<00:00, 926.37it/s] \n",
      "Populate matrix: 100%|██████████| 52046/52046 [00:56<00:00, 914.54it/s]\n",
      "Populate matrix: 100%|██████████| 54721/54721 [01:00<00:00, 901.24it/s]\n",
      "Populate matrix: 100%|██████████| 58439/58439 [01:02<00:00, 941.58it/s]\n",
      "Populate matrix: 100%|██████████| 62241/62241 [01:04<00:00, 964.21it/s]\n",
      "Populate matrix: 100%|██████████| 67361/67361 [01:08<00:00, 988.87it/s] \n",
      "Populate matrix: 100%|██████████| 70501/70501 [01:08<00:00, 1036.26it/s]\n",
      "Populate matrix: 100%|██████████| 75717/75717 [01:13<00:00, 1034.80it/s]\n",
      "Populate matrix: 100%|██████████| 81228/81228 [01:18<00:00, 1038.91it/s]\n",
      "Populate matrix: 100%|██████████| 84496/84496 [01:23<00:00, 1017.78it/s]\n",
      "Populate matrix: 100%|██████████| 89168/89168 [01:27<00:00, 1022.31it/s]\n",
      "Populate matrix: 100%|██████████| 93185/93185 [01:30<00:00, 1027.95it/s]\n",
      "Populate matrix: 100%|██████████| 100470/100470 [01:39<00:00, 1008.00it/s]\n",
      "Populate matrix: 100%|██████████| 103192/103192 [01:40<00:00, 1031.33it/s]\n",
      "Populate matrix: 100%|██████████| 106454/106454 [01:40<00:00, 1055.65it/s]\n",
      "Populate matrix: 100%|██████████| 106557/106557 [01:38<00:00, 1077.60it/s]\n",
      "For each year in range: 100%|██████████| 21/21 [25:02<00:00, 71.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import novelpy\n",
    "\n",
    "# all the cooc possible not including the one done above\n",
    "\n",
    "ref_cooc = novelpy.utils.cooc_utils.create_cooc(\n",
    "                 collection_name = \"Ref_Journals_sample\",\n",
    "                 year_var=\"year\",\n",
    "                 var = \"c04_referencelist\",\n",
    "                 sub_var = \"item\",\n",
    "                 time_window = range(1995,2016),\n",
    "                 weighted_network = True, self_loop = True)\n",
    "\n",
    "ref_cooc.main()\n",
    "\n",
    "ref_cooc = novelpy.utils.cooc_utils.create_cooc(\n",
    "                 collection_name = \"Ref_Journals_sample\",\n",
    "                 year_var=\"year\",\n",
    "                 var = \"c04_referencelist\",\n",
    "                 sub_var = \"item\",\n",
    "                 time_window = range(1995,2016),\n",
    "                 weighted_network = False, self_loop = False)\n",
    "\n",
    "ref_cooc.main()\n",
    "\n",
    "ref_cooc = novelpy.utils.cooc_utils.create_cooc(\n",
    "                 collection_name = \"Meshterms_sample\",\n",
    "                 year_var=\"year\",\n",
    "                 var = \"Mesh_year_category\",\n",
    "                 sub_var = \"descUI\",\n",
    "                 time_window = range(1995,2016),\n",
    "                 weighted_network = True, self_loop = True)\n",
    "\n",
    "ref_cooc.main()\n",
    "\n",
    "ref_cooc = novelpy.utils.cooc_utils.create_cooc(\n",
    "                 collection_name = \"Meshterms_sample\",\n",
    "                 year_var=\"year\",\n",
    "                 var = \"Mesh_year_category\",\n",
    "                 sub_var = \"descUI\",\n",
    "                 time_window = range(1995,2016),\n",
    "                 weighted_network = False, self_loop = False)\n",
    "\n",
    "ref_cooc.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this you can run the indicators. Note that for computation purpose and storage we compute it for only 2 years but you can compute it for atleast 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:01<00:00, 39144.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [33:13<00:00, 99.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2000 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 94.02it/s]\n",
      "100%|██████████| 20/20 [00:30<00:00,  1.52s/it]\n",
      "100%|██████████| 19378929/19378929 [2:22:45<00:00, 2262.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [03:03<00:00, 271.62it/s]\n",
      "Computing indicator for window of time:  17%|█▋        | 1/6 [3:02:13<15:11:08, 10933.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:01<00:00, 31269.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [38:00<00:00, 114.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 83.60it/s]\n",
      "100%|██████████| 20/20 [00:34<00:00,  1.72s/it]\n",
      "100%|██████████| 20434046/20434046 [2:31:44<00:00, 2244.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [02:49<00:00, 307.08it/s]\n",
      "Computing indicator for window of time:  33%|███▎      | 2/6 [6:18:15<12:41:23, 11420.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 54721/54721 [00:00<00:00, 55151.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [35:14<00:00, 105.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2002 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 96.62it/s]\n",
      "100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n",
      "100%|██████████| 20825880/20825880 [2:32:48<00:00, 2271.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2002  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 54721/54721 [02:52<00:00, 317.49it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 3/6 [9:32:23<9:36:13, 11524.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 58439/58439 [00:01<00:00, 53564.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [38:28<00:00, 115.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2003 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 93.46it/s]\n",
      "100%|██████████| 20/20 [00:34<00:00,  1.75s/it]\n",
      "100%|██████████| 22103148/22103148 [2:43:02<00:00, 2259.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2003  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 58439/58439 [03:06<00:00, 313.74it/s]\n",
      "Computing indicator for window of time:  67%|██████▋   | 4/6 [13:00:24<6:36:43, 11901.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 62241/62241 [00:01<00:00, 55771.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [40:37<00:00, 121.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2004 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 90.09it/s]\n",
      "100%|██████████| 20/20 [00:36<00:00,  1.84s/it]\n",
      "100%|██████████| 22850833/22850833 [2:48:09<00:00, 2264.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2004  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 62241/62241 [03:22<00:00, 307.65it/s]\n",
      "Computing indicator for window of time:  83%|████████▎ | 5/6 [16:36:01<3:24:35, 12275.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 67361/67361 [00:01<00:00, 39728.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [43:39<00:00, 130.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/Mesh_year_category/\n",
      "Getting the uzzi novelty score for combination of items in 2005 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 71.00it/s]\n",
      "100%|██████████| 20/20 [00:41<00:00,  2.06s/it]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "# Uzzi et al.(2013) Meshterms_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Uzzi = novelpy.indicators.Uzzi2013(collection_name = \"Meshterms_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"Mesh_year_category\",\n",
    "                                           sub_variable = \"descUI\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           density = True)\n",
    "    Uzzi.get_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:00<00:00, 176225.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [00:46<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2000 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 216.88it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.23it/s]\n",
      "100%|██████████| 850989/850989 [06:29<00:00, 2186.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [00:02<00:00, 18041.67it/s]\n",
      "Computing indicator for window of time:  17%|█▋        | 1/6 [07:47<38:59, 467.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:00<00:00, 204598.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [00:47<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 185.06it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 24.93it/s]\n",
      "100%|██████████| 885779/885779 [06:49<00:00, 2163.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [00:02<00:00, 18637.14it/s]\n",
      "Computing indicator for window of time:  33%|███▎      | 2/6 [15:57<32:02, 480.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 54721/54721 [00:00<00:00, 199978.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [00:54<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2002 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 204.06it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 21.08it/s]\n",
      "100%|██████████| 1042040/1042040 [08:07<00:00, 2136.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2002  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 54721/54721 [00:03<00:00, 14172.86it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 3/6 [25:41<26:23, 527.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 58439/58439 [00:00<00:00, 176552.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [01:05<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2003 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 142.66it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 13.77it/s]\n",
      "100%|██████████| 1043240/1043240 [08:28<00:00, 2053.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2003  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 58439/58439 [00:03<00:00, 14904.15it/s]\n",
      "Computing indicator for window of time:  67%|██████▋   | 4/6 [35:55<18:43, 561.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 62241/62241 [00:00<00:00, 179887.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [01:15<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2004 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 137.42it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 14.41it/s]\n",
      "100%|██████████| 1141269/1141269 [08:47<00:00, 2165.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2004  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 62241/62241 [00:03<00:00, 16887.31it/s]\n",
      "Computing indicator for window of time:  83%|████████▎ | 5/6 [46:32<09:48, 588.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year uzzi\n",
      "cooc loaded !\n",
      "loading items for papers in 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 67361/67361 [00:00<00:00, 220061.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Creating sample for Uzzi et al. (2013) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create sample network: 100%|██████████| 20/20 [01:37<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! Saved in Data/cooc_sample/c04_referencelist/\n",
      "Getting the uzzi novelty score for combination of items in 2005 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get sample network: 100%|██████████| 20/20 [00:00<00:00, 173.89it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.28it/s]\n",
      "100%|██████████| 1619015/1619015 [11:45<00:00, 2295.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the uzzi novelty indicator for 2005  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 67361/67361 [00:05<00:00, 11434.59it/s]\n",
      "Computing indicator for window of time: 100%|██████████| 6/6 [1:00:32<00:00, 605.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/uzzi/c04_referencelist\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "\n",
    "# Uzzi et al.(2013) Ref_Journals_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Uzzi = novelpy.indicators.Uzzi2013(collection_name = \"Ref_Journals_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"c04_referencelist\",\n",
    "                                           sub_variable = \"item\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           density = True)\n",
    "    Uzzi.get_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year foster\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:00<00:00, 62650.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Create empty df ...\n",
      "Empty df created !\n",
      "Compute community and community appartenance for 1995-2000\n",
      "Get Partition of community ...\n",
      "Partition Done !\n",
      "Updating the score matrix ...\n",
      "Done ...\n",
      "Done !\n",
      "Getting the foster novelty score for combination of items in 2000 ...\n",
      "Done !\n",
      "Attributing the foster novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [00:22<00:00, 2200.21it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 1/2 [11:47<11:47, 707.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/foster/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year foster\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:06<00:00, 7609.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Create empty df ...\n",
      "Empty df created !\n",
      "Compute community and community appartenance for 1995-2001\n",
      "Get Partition of community ...\n",
      "Partition Done !\n",
      "Updating the score matrix ...\n",
      "Done ...\n",
      "Done !\n",
      "Getting the foster novelty score for combination of items in 2001 ...\n",
      "Done !\n",
      "Attributing the foster novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [00:25<00:00, 2036.08it/s]\n",
      "Computing indicator for window of time: 100%|██████████| 2/2 [24:12<00:00, 726.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/foster/Mesh_year_category\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Foster et al.(2015) Meshterms_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Foster = novelpy.indicators.Foster2015(collection_name = \"Meshterms_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"Mesh_year_category\",\n",
    "                                           sub_variable = \"descUI\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           starting_year = 1995,\n",
    "                                           community_algorithm = \"Louvain\",\n",
    "                                           density = True)\n",
    "    Foster.get_indicator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year foster\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:07<00:00, 6541.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Create empty df ...\n",
      "Empty df created !\n",
      "Compute community and community appartenance for 1995-2000\n",
      "Get Partition of community ...\n",
      "Partition Done !\n",
      "Updating the score matrix ...\n",
      "Done ...\n",
      "Done !\n",
      "Getting the foster novelty score for combination of items in 2000 ...\n",
      "Done !\n",
      "Attributing the foster novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [00:00<00:00, 52076.38it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 1/2 [00:43<00:43, 43.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/foster/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year foster\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:00<00:00, 363378.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Create empty df ...\n",
      "Empty df created !\n",
      "Compute community and community appartenance for 1995-2001\n",
      "Get Partition of community ...\n",
      "Partition Done !\n",
      "Updating the score matrix ...\n",
      "Done ...\n",
      "Done !\n",
      "Getting the foster novelty score for combination of items in 2001 ...\n",
      "Done !\n",
      "Attributing the foster novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [00:00<00:00, 104310.65it/s]\n",
      "Computing indicator for window of time: 100%|██████████| 2/2 [01:15<00:00, 37.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/foster/c04_referencelist\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Foster = novelpy.indicators.Foster2015(collection_name = \"Ref_Journals_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"c04_referencelist\",\n",
    "                                           sub_variable = \"item\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           starting_year = 1995,\n",
    "                                           community_algorithm = \"Louvain\",\n",
    "                                           density = True)\n",
    "    Foster.get_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year lee\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:01<00:00, 35297.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the lee novelty score for combination of items in 2000 ...\n",
      "comb_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\novelty\\Lib\\site-packages\\scipy\\sparse\\_base.py:713: RuntimeWarning: divide by zero encountered in divide\n",
      "  recip = np.true_divide(1., other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle dump\n",
      "Matrice done !\n",
      "Attributing the lee novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [01:55<00:00, 432.19it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 1/2 [02:18<02:18, 138.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/lee/Mesh_year_category\n",
      "Done !\n",
      "loading cooc for indicator focal year lee\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:01<00:00, 34835.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the lee novelty score for combination of items in 2001 ...\n",
      "comb_scores\n",
      "pickle dump\n",
      "Matrice done !\n",
      "Attributing the lee novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [02:03<00:00, 419.78it/s]\n",
      "Computing indicator for window of time: 100%|██████████| 2/2 [04:40<00:00, 140.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/lee/Mesh_year_category\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "# Lee et al.(2015) Meshterms_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Lee = novelpy.indicators.Lee2015(collection_name = \"Meshterms_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"Mesh_year_category\",\n",
    "                                           sub_variable = \"descUI\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           density = True)\n",
    "    Lee.get_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing indicator for window of time:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year lee\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:00<00:00, 374169.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the lee novelty score for combination of items in 2000 ...\n",
      "comb_scores\n",
      "pickle dump\n",
      "Matrice done !\n",
      "Attributing the lee novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [00:02<00:00, 24785.71it/s]\n",
      "Computing indicator for window of time:  50%|█████     | 1/2 [00:05<00:05,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/lee/c04_referencelist\n",
      "Done !\n",
      "loading cooc for indicator focal year lee\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:00<00:00, 341774.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the lee novelty score for combination of items in 2001 ...\n",
      "comb_scores\n",
      "pickle dump\n",
      "Matrice done !\n",
      "Attributing the lee novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [00:02<00:00, 20179.48it/s]\n",
      "Computing indicator for window of time: 100%|██████████| 2/2 [00:10<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/lee/c04_referencelist\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "\n",
    "\n",
    "# Lee et al.(2015) Ref_Journals_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002), desc = \"Computing indicator for window of time\"):\n",
    "    Lee = novelpy.indicators.Lee2015(collection_name = \"Ref_Journals_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"c04_referencelist\",\n",
    "                                           sub_variable = \"item\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           density = True)\n",
    "    Lee.get_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year wang\n",
      "Calculate past matrix for Wang et al.(2017)\n",
      "Calculate futur matrix for Wang et al.(2017)\n",
      "Calculate difficulty matrix for Wang et al.(2017)\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:00<00:00, 74303.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the wang novelty score for combination of items in 2000 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\github\\novelpy\\novelpy\\indicators\\Wang2017.py:132: SparseEfficiencyWarning: Comparing a sparse matrix with a scalar greater than zero using < is inefficient, try using >= instead.\n",
      "  self.futur_adj[self.futur_adj < self.n_reutilisation] = 0\n",
      "d:\\anaconda3\\envs\\novelty\\Lib\\site-packages\\scipy\\sparse\\_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice done !\n",
      "Attributing the wang novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [11:11<00:00, 74.28it/s]\n",
      " 50%|█████     | 1/2 [16:41<16:41, 1001.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/wang/Mesh_year_category_3_1_restricted50\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year wang\n",
      "Calculate past matrix for Wang et al.(2017)\n",
      "Calculate futur matrix for Wang et al.(2017)\n",
      "Calculate difficulty matrix for Wang et al.(2017)\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:01<00:00, 29001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the wang novelty score for combination of items in 2001 ...\n",
      "Matrice done !\n",
      "Attributing the wang novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [10:12<00:00, 84.91it/s] \n",
      "100%|██████████| 2/2 [32:07<00:00, 963.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/wang/Mesh_year_category_3_1_restricted50\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Wang et al.(2017) Meshterms_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002)):\n",
    "    Wang = novelpy.indicators.Wang2017(collection_name = \"Meshterms_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"Mesh_year_category\",\n",
    "                                           sub_variable = \"descUI\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           time_window_cooc = 3,\n",
    "                                           n_reutilisation = 1,\n",
    "                                           starting_year = 1995,\n",
    "                                           density = True)\n",
    "    Wang.get_indicator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year wang\n",
      "Calculate past matrix for Wang et al.(2017)\n",
      "Calculate futur matrix for Wang et al.(2017)\n",
      "Calculate difficulty matrix for Wang et al.(2017)\n",
      "cooc loaded !\n",
      "loading items for papers in 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 49872/49872 [00:00<00:00, 377818.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the wang novelty score for combination of items in 2000 ...\n",
      "Matrice done !\n",
      "Attributing the wang novelty indicator for 2000  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 49872/49872 [00:02<00:00, 21245.62it/s]\n",
      " 50%|█████     | 1/2 [01:19<01:19, 79.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/wang/c04_referencelist_3_1_restricted50\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cooc for indicator focal year wang\n",
      "Calculate past matrix for Wang et al.(2017)\n",
      "Calculate futur matrix for Wang et al.(2017)\n",
      "Calculate difficulty matrix for Wang et al.(2017)\n",
      "cooc loaded !\n",
      "loading items for papers in 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_papers_item: 100%|██████████| 52046/52046 [00:00<00:00, 337442.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_loaded !\n",
      "Getting the wang novelty score for combination of items in 2001 ...\n",
      "Matrice done !\n",
      "Attributing the wang novelty indicator for 2001  papers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 52046/52046 [00:02<00:00, 20972.37it/s]\n",
      "100%|██████████| 2/2 [02:43<00:00, 81.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in Result/wang/c04_referencelist_3_1_restricted50\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "# Wang et al.(2017) Ref_Journals_sample\n",
    "for focal_year in tqdm.tqdm(range(2000,2002)):\n",
    "    Wang = novelpy.indicators.Wang2017(collection_name = \"Ref_Journals_sample\",\n",
    "                                           id_variable = 'PMID',\n",
    "                                           year_variable = 'year',\n",
    "                                           variable = \"c04_referencelist\",\n",
    "                                           sub_variable = \"item\",\n",
    "                                           focal_year = focal_year,\n",
    "                                           time_window_cooc = 3,\n",
    "                                           n_reutilisation = 1,\n",
    "                                           starting_year = 1995,\n",
    "                                           density = True)\n",
    "    Wang.get_indicator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"computation-for-text-based-novelty-indicators\"></a>\n",
    "## Computation for text based novelty indicators\n",
    "\n",
    "Novelpy supports two text based indicator: Shibayama et al. (2021) and Pelletier et Wirtz (2023).\n",
    "\n",
    "Both these indicators first require to embed articles using their text either on their Abstract, title or keywords. We have an argument for each of the text unit although we recommend to just combine every text you want in one field and use only one (For example in your dict have {\"abstract_variable\":Abstract+title+keywords}). We make use of the pretrain of Scipy using en_core_sci_lg-0.5.3\n",
    "Note that this will only work on english paper but we made the pretrain_path flexible enough so that you can use your own embedding. For each article we then compute the centroid of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelpy.utils.embedding import Embedding\n",
    "\n",
    "embedding = Embedding(\n",
    "            year_variable = 'year',\n",
    "            time_range = range(2000,2002),\n",
    "            id_variable = 'PMID',\n",
    "            references_variable = 'refs_pmid_wos',\n",
    "            pretrain_path = 'en_core_sci_lg-0.5.3/en_core_sci_lg/en_core_sci_lg-0.5.3',\n",
    "            title_variable = 'ArticleTitle',\n",
    "            abstract_variable = 'a04_abstract',\n",
    "            abstract_subvariable = 'AbstractText',\n",
    "            keywords_variable = None,\n",
    "            keywords_subvariable = None)\n",
    "\n",
    "# articles\n",
    "\n",
    "embedding.get_articles_centroid(\n",
    "      collection_articles = 'Title_abs_sample',\n",
    "      collection_embedding = 'embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the centroid for the focal papers is calculated you can directly run Shibayama et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import novelpy\n",
    "import tqdm\n",
    "\n",
    "for focal_year in tqdm.tqdm(range(1995,2002), desc = \"Computing indicator for window of time\"):\n",
    " shibayama = novelpy.indicators.Shibayama2021(\n",
    "      collection_name = 'Citation_net_sample',\n",
    "      collection_embedding_name = 'embedding',\n",
    "      id_variable = 'PMID',\n",
    "      year_variable = 'year',\n",
    "      ref_variable = 'refs_pmid_wos',\n",
    "      entity = ['title_embedding','abstract_embedding'],\n",
    "      focal_year = focal_year,\n",
    "      density = True)\n",
    "\n",
    " shibayama.get_indicator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Pelletier et Wirtz (2023) indicator you need to add a step to create the profile of authors for each year. Meaning you create a dict for each author for a given year that contains information on the centroid of the articles he/she co-authored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelpy.utils import Embedding\n",
    "from novelpy.utils import create_authors_past\n",
    "import novelpy\n",
    "\n",
    "# First step is to create a collection where each doc contains the author ID and its list of document he coauthored\n",
    "clean = create_authors_past(\n",
    "                             collection_name = \"authors_sample\",\n",
    "                             id_variable = \"PMID\",\n",
    "                             variable = \"a02_authorlist\",\n",
    "                             sub_variable = \"AID\")\n",
    "\n",
    "clean.author2paper()\n",
    "clean.update_db()\n",
    "\n",
    "embedding = Embedding(\n",
    "      year_variable = 'year',\n",
    "      id_variable = 'PMID',\n",
    "      references_variable = 'refs_pmid_wos',\n",
    "      pretrain_path = r'en_core_sci_lg-0.5.3\\en_core_sci_lg\\en_core_sci_lg-0.5.3',\n",
    "      title_variable = 'ArticleTitle',\n",
    "      abstract_variable = 'a04_abstract',\n",
    "      abstract_subvariable = 'AbstractText',\n",
    "      aut_id_variable = 'AID',\n",
    "      aut_pubs_variable = 'doc_list')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "embedding.get_articles_centroid(\n",
    "      collection_articles = 'Title_abs_sample',\n",
    "      collection_embedding = 'embedding')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "embedding.feed_author_profile(\n",
    "    aut_id_variable = 'AID',\n",
    "    aut_pubs_variable = 'doc_list',\n",
    "    collection_authors = 'authors_sample_cleaned',\n",
    "    collection_embedding = 'embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this data is created you can run Pelletier et Wirtz (2023) indicator the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelpy.indicators.Author_proximity import Author_proximity\n",
    "\n",
    "for year in range(2000,2002):\n",
    "    author =  Author_proximity(\n",
    "                         collection_name = 'authors_sample',\n",
    "                         id_variable = 'PMID',\n",
    "                         year_variable = 'year',\n",
    "                         aut_list_variable = 'a02_authorlist',\n",
    "                         aut_id_variable = 'AID',\n",
    "                         entity = ['title','abstract'],\n",
    "                         focal_year = year,\n",
    "                         windows_size = 5,\n",
    "                       density = True)\n",
    "\n",
    "    author.get_indicator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"computation-for-disruption-indicators\"></a>\n",
    "## Computation for disruption indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import novelpy\n",
    "\n",
    "clean = novelpy.utils.preprocess_disruptiveness.create_citation_network(collection_name = \"Citation_net_sample\",\n",
    "                                                                        id_variable = \"PMID\", variable = \"refs_pmid_wos\")\n",
    "clean.id2citedby()\n",
    "clean.update_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import novelpy\n",
    "\n",
    "\n",
    "for year in range(2000,2011):\n",
    "    disruptiveness = novelpy.Disruptiveness(\n",
    "        collection_name = 'Citation_net_sample_cleaned',\n",
    "        focal_year = year,\n",
    "        id_variable = 'PMID',\n",
    "        refs_list_variable ='refs',\n",
    "        cits_list_variable = 'cited_by',\n",
    "        year_variable = 'year')\n",
    "    \n",
    "    disruptiveness.get_indicators(parallel = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"To go further\"></a>\n",
    "## To go further\n",
    "\n",
    "We have added some features that might be of some use. The first things is to compute indicators only on a list of papers. This can be done with the argument \"list_ids\" for any indicator computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute the lee et al. indicator for papers with PMID in [\"10592257\",\"10594130\"]. Make sure that the ids correspond to the focal_year\n",
    "\n",
    "focal_year = 2000\n",
    "\n",
    "Lee = novelpy.indicators.Lee2015(collection_name = \"Ref_Journals_sample\",\n",
    "                                        id_variable = 'PMID',\n",
    "                                        year_variable = 'year',\n",
    "                                        variable = \"c04_referencelist\",\n",
    "                                        sub_variable = \"item\",\n",
    "                                        focal_year = focal_year,\n",
    "                                        density = True,\n",
    "                                        list_ids=[\"10592257\",\"10594130\"])\n",
    "\n",
    "Lee.get_indicator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another argument that can be changed is density. To give you the most info density=True keeps the novelty score of each combination in the paper giving you a distribution of novelty score. If you only want the score for a paper and not the distribution then put density=False."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novelty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
